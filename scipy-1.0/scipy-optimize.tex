\newcommand{\RR}{\ensuremath{\mathbb{R}}}
The \texttt{scipy.optimize} module provides functions for the numerical
solution of several classes of root finding and optimization problems.
Here we highlight recent additions through SciPy 1.0.

%\subsubsection{Root Finding}
%The general ``root finding'' problem is to find a root $\mathbf{x} \in \RR^m$ of $\mathbf{f}: \RR^m \rightarrow \RR^m$, that is, to solve
%\begin{equation}
%\mathbf{f}(\mathbf{x}) = \mathbf{0}
%\end{equation}
%for a solution $\mathbf{x}$.\footnote{Equivalently the problem is to simultaneously find the roots $x_i \in \RR$ of several scalar functions $f_i : \RR \rightarrow \RR$, that is, to solve $f_i(x_0, x_1, \dots, x_{m-1}) = 0$ for $x_i$, $i \in \{0, 1, \dots {m-1}\}$.} The function \texttt{scipy.optimize.root} provides a common interface to several algorithms for solving problems of this type. For the special case\footnote{that is, to solve a single scalar equation $f(x) = 0$ for a single scalar variable $x$} $m = 1$, any one of several specialized functions \texttt{brentq}, \texttt{brenth}, \texttt{ridder}, \texttt{bisect}, or \texttt{newton} may provide improved performance or accuracy. (Have there been any recent improvements? Do we want to summarize the methods as @antonior92 has done for $minimize$? Do we have to explain that these methods only provide \emph{one} solution, and that they are iterative based on a user-provided guess? Do we have to explain the notion of tolerance? Is this a good template for the beginning of the following subsections?)


\subsubsection*{Linear Optimization}

A new interior-point optimizer for continuous linear programming problems, \texttt{linprog} with \texttt{method='interior-point'}, was released with SciPy 1.0. Implementing the core algorithm of the commercial solver MOSEK \cite{andersen2000mosek}, it solves all of the 90+ NETLIB LP benchmark problems \cite{netlib} tested. Unlike some interior point methods, this homogeneous self-dual formulation provides certificates of infeasibility or unboundedness as appropriate. 

A presolve routine \cite{andersen1995presolving} solves trivial problems and otherwise performs problem simplifications, such as bound tightening and removal of fixed variables, and one of several routines for eliminating redundant equality constraints is automatically chosen to reduce the chance of numerical difficulties caused by singular matrices. Although the main solver implementation is pure Python, end-to-end sparse matrix support and heavy use of SciPy's compiled linear system solvers---often for the same system with multiple right hand sides due to the predictor-corrector approach---provide speed sufficient for problems with tens of thousands of variables and constraints.

Compared to the previously implemented simplex method, the new interior-point method is faster for all but the smallest problems, and is suitable for solving medium- and large-sized problems on which the existing simplex implementation fails. However, the interior point method typically returns a solution near the center of an optimal face, yet basic solutions are often preferred for sensitivity analysis and for use in mixed integer programming algorithms. This motivates the need for a crossover routine or a new implementation of the simplex method for sparse problems in a future release, either of which would require an improved sparse linear system solver with efficient support for rank-one updates

\subsubsection*{Nonlinear Optimization}
\paragraph{Local Minimization}

The \texttt{minimize} function provides methods for finding local minima of
nonlinear optimization problems. It unifies several methods with a common 
interface in order to facilitate interchanging between solvers with different
characteristics. Characteristics of the different methods are summarized in 
Table~\ref{tab:minimize-si}.
%% Currently, this introduces a ton of whitespace around a very simple expression (min f(x)). The reader can easily find the standard of meaning of `nonlinear programming', so I believe it should be removed. If we decide that it is appropriate to include, then we should add the entire problem statement - including constraints - and we should also include the entire linear programming problem statement in the previous section.
% summarizes all the methods available for solving minimization problems of the type:
%\begin{equation}
%  \label{eq:minimization-prob}
%  \min_x f(x)
%\end{equation}
%where $f$ is a multivariate function $f: \mathbb{R}^n \rightarrow \mathbb{R}$ and $x \in \mathbb{R}^n$.
%%  Without the problem statement this sentence isn't really appropriate.
%\texttt{COBYLA} and \texttt{SLSQP} methods support nonlinear constraints, \texttt{L-BFGS-B} and \texttt{TNC} allow box constraints $x^l \le x \le x^u$,
%and the remaining methods are for unconstrained problems.

% The available methods implement a variety of solution strategies.
Derivative-free methods (e.g. \texttt{Nelder-Mead}, \texttt{Powell} and \texttt{COBYLA}) are appropriate for minimizing non-differentiable or
noisy objective functions. When derivatives are available, however, other methods offer faster convergence rates
and have proven convergence properties. 
The derivative-based methods start with an initial guess and refine it iteratively, seeking
a local solution to the optimization problem. Each of these algorithms implements one of two complementary strategies:
line-search or trust-region. At each iteration, the line-search (LS) methods choose a direction
and approximate the optimal point in the given direction. Trust-region (TR) methods, on the other
hand, choose a ``trust-region'' region for which a local model is valid and approximate the best point
inside.

One recently-added trust-region method is \texttt{trust-exact},
which achieves fast convergence by solving the trust-region subproblem almost exactly.
Unfortunately, it requires the Hessian to be stored and factored every iteration, which may preclude
the solution of large problems (e.g.~problems with more than 1000 variables).
Other methods are appropriate for large-scale problems, including
\texttt{CG}, which does not use second derivatives and thus has low memory requirements, and \texttt{L-BFGS-B}, which maintains a simple and compact representation of the Hessian.
\texttt{Newton-CG}, \texttt{trust-ncg} and \texttt{trust-krylov} use second order derivatives to achieve faster
convergence, but are still appropriate for large problems because they factorize the Hessian in an inexact and iterative way that does not require the Hessian to be stored.
The method \texttt{trust-krylov}, introduced in the latest release, is a good compromise between
\texttt{trust-ncg} and \texttt{trust-exact}: it provides a more accurate solution to the trust-region
subproblem than \texttt{trust-ncg}, but it does not require the Hessian to be stored and factored as in \texttt{trust-exact}.

While most \texttt{minimize} development prior to SciPy 1.0 has focused on unconstrained minimization, 
% methods \texttt{SLSQP} and \texttt{COBYLA}\footnote{We note that any equality constraint $c_{\text{eq}}(x) = 0$ can be expressed as two inequality constraints $c_{\text{eq}}(x) \leq 0$ and $-c_{\text{eq}}(x) \leq 0$} 
\texttt{SLSQP} supports fully general nonlinear programming. However, it does not provide special treatment for sparsity, limiting its utility to small problems. Accordingly, ongoing development efforts for \texttt{minimize} are focused on the addition of nonlinear programming algorithms for large, sparse problems. 


\paragraph{Global Minimization}
As \texttt{minimize} only seeks a local minimum, some problems require the use of a global optimization routine to find the minimum of the objective function over the set of all decision variable values, especially if the objective function possesses many local minima that other solvers could get stuck in. % e.g. if there is concern that `minimize` could get stuck in an unacceptable local minimum?
The \texttt{brute} function performs a grid search over the entire domain, and the best grid point is ``polished'' by a local minimizer. However, this approach becomes prohibitively expensive as the problem dimensionality increases.
% As far as I understand how brute works, the run time does not depend on the number of extrema, as it only polishes the best one
% , or if the objective function has many extrema. 
To address this, the
\texttt{basinhopping} \cite{Wales1997} function uses random perturbation of the decision variables in conjunction with local minimization. The acceptance of the perturbed coordinates is dictated by the Metropolis test typically used in Monte Carlo simulations. 
\texttt{differential\textunderscore evolution} \cite{Wormington1999,Storn1997} is a stochastic solver that improves by gradual evolution of a population of candidate solutions. In each iteration, trial candidates are generated by combination of candidates from the existing population; if the trial candidates represent an improvement then the population is updated. 
% Is the following a unique feature of differential_evolution? If so, state it (although it seems that neither `brute`or `basinhopping` inherently require the a differentiable problem). If not, why mention it? 
% \texttt{differential\textunderscore evolution} does not require that the objective function be differentiable.
%  basinhopping may need differentiable objective for the local minimization.
Most recently, the SciPy benchmark suite gained a comprehensive set of 196 global optimization problems
% They're ``comprehensive''
% of varying difficulties, 
% that can be used to evaluate the performance of the solvers. 
%This suite is used to decide
for tracking the performance of existing solvers over time and for evaluating whether the performance of new solvers merits inclusion in the package. 
% have good enough performance to be added to the package.
